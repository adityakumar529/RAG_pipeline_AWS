{
  "metadata": {
    "kernelspec": {
      "name": "xpython",
      "display_name": "Python 3.13 (XPython)",
      "language": "python"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.13.1"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "68f15388-97bf-422f-92a3-c299a6a33d43",
      "cell_type": "code",
      "source": "# lambda_function.py\n# -*- coding: utf-8 -*-\n\nimport os\nimport json\nimport time\nimport base64\nimport mimetypes\nimport logging\nimport re\nfrom typing import Optional, Dict, List, Any\n\nimport boto3\nfrom botocore.config import Config\nimport requests\nfrom requests.adapters import HTTPAdapter\nfrom urllib3.util.retry import Retry\n\n# ───────────────────────── config / logging ─────────────────────────\nlog = logging.getLogger()\nlog.setLevel(logging.INFO)\n\n# Required (DO NOT hardcode real values in public repo)\nS3_BUCKET   = os.getenv(\"S3_BUCKET\", \"\").strip()\nSN_INSTANCE = os.getenv(\"SN_INSTANCE\", \"\").strip()\nSN_USER     = os.getenv(\"SN_USER\", \"\").strip()\n\n# Credentials (prefer Secrets Manager)\nSECRET_ID = os.getenv(\"SECRET_ID\", \"\").strip()   # preferred\nSN_PASS   = os.getenv(\"SN_PASS\", \"\").strip()     # fallback (discouraged for production)\n\n# KB restriction (no client-specific default in public repo)\nKNOWLEDGE_BASE_NAME = os.getenv(\"KNOWLEDGE_BASE_NAME\", \"\").strip()\n\n# Optional\nDEST_PREFIX        = os.getenv(\"DEST_PREFIX\", \"\").strip()\nPAGE_SIZE          = int(os.getenv(\"PAGE_SIZE\", \"200\"))\nARTICLES_LIMIT     = int(os.getenv(\"ARTICLES_LIMIT\", \"0\"))  # 0 = no cap\nSTRICT_PUBLISHED   = os.getenv(\"STRICT_PUBLISHED\", \"true\").lower() == \"true\"\nSTOP_AFTER_SECONDS = int(os.getenv(\"STOP_AFTER_SECONDS\", \"840\"))  # ~14m\n\n# File/sidecar controls\nMAX_FILE_BYTES = int(os.getenv(\"MAX_FILE_BYTES\", \"52428800\"))  # 50 MB\nATTACH_EXT_WHITELIST = [\n    e.strip().lower()\n    for e in os.getenv(\n        \"ATTACH_EXT_WHITELIST\",\n        \"pdf,doc,docx,xls,xlsx,ppt,pptx,html,jpg,jpeg,png,gif,webp,tif,tiff,svg,csv,txt,rtf,odt,ods,odp,zip\"\n    ).split(\",\")\n    if e.strip()\n]\n\nTITLE_MAX_CHARS        = int(os.getenv(\"TITLE_MAX_CHARS\", \"200\"))\nLOG_METADATA_BYTES     = os.getenv(\"LOG_METADATA_BYTES\", \"false\").lower() == \"true\"\nGENERATE_TEXT_FROM_HTML = os.getenv(\"GENERATE_TEXT_FROM_HTML\", \"false\").lower() == \"true\"\nMAX_METADATA_BYTES     = int(os.getenv(\"MAX_METADATA_BYTES\", \"1800\"))  # budget for metadataAttributes JSON\n\n# Public-safe URL template (no client paths)\nSN_URL_TEMPLATE = os.getenv(\n    \"SN_URL_TEMPLATE\",\n    \"{base}/kb_view.do?sysparm_article={number}\"\n)\n\n# ───────────────────────── endpoints/clients ─────────────────────\nSN_BASE             = f\"https://{SN_INSTANCE}.service-now.com\" if SN_INSTANCE else \"\"\nKB_TABLE_API        = f\"{SN_BASE}/api/now/table/kb_knowledge\" if SN_BASE else \"\"\nKB_BASE_TABLE       = f\"{SN_BASE}/api/now/table/kb_knowledge_base\" if SN_BASE else \"\"\nARTICLE_CONTENT_API = f\"{SN_BASE}/api/sn_km_api/v1/knowledge/articles/\" if SN_BASE else \"\"\nATTACH_LIST_API     = f\"{SN_BASE}/api/now/attachment\" if SN_BASE else \"\"\nATTACH_DOWNLOAD     = f\"{SN_BASE}/api/now/attachment/\" if SN_BASE else \"\"\n\nboto_cfg = Config(retries={\"max_attempts\": 5, \"mode\": \"standard\"})\ns3       = boto3.client(\"s3\", config=boto_cfg)\nsecrets  = boto3.client(\"secretsmanager\", config=boto_cfg)\n\nmimetypes.init()\n\n# ───────────────────────── HTTP (retrying session) ──────────────\ndef _requests_session():\n    s = requests.Session()\n    retry = Retry(\n        total=5,\n        backoff_factor=0.5,\n        status_forcelist=[429, 500, 502, 503, 504],\n        allowed_methods=(\"GET\",),\n    )\n    s.mount(\"https://\", HTTPAdapter(max_retries=retry))\n    return s\n\nHTTP = _requests_session()\n\n# ───────────────────────── safety helpers ─────────────────────────\ndef validate_runtime_config() -> Optional[dict]:\n    \"\"\"\n    Return an error dict if config is invalid, otherwise None.\n    (Avoid printing env values in errors/logs to keep public-safe.)\n    \"\"\"\n    missing = []\n    if not S3_BUCKET:\n        missing.append(\"S3_BUCKET\")\n    if not SN_INSTANCE:\n        missing.append(\"SN_INSTANCE\")\n    if not SN_USER:\n        missing.append(\"SN_USER\")\n    if not (SECRET_ID or SN_PASS):\n        missing.append(\"SECRET_ID (preferred) or SN_PASS\")\n\n    if missing:\n        return {\n            \"status\": \"error\",\n            \"type\": \"config_error\",\n            \"message\": \"Missing required configuration.\",\n            \"missing\": missing,\n        }\n    if not KNOWLEDGE_BASE_NAME:\n        return {\n            \"status\": \"error\",\n            \"type\": \"config_error\",\n            \"message\": \"KNOWLEDGE_BASE_NAME must be provided (no default in public repo).\",\n            \"missing\": [\"KNOWLEDGE_BASE_NAME\"],\n        }\n    return None\n\ndef mask(s: str, keep: int = 4) -> str:\n    if not s:\n        return \"\"\n    return s[:keep] + \"...\" if len(s) > keep else s\n\n# ───────────────────────── helpers ──────────────────────────────\ndef _prefix() -> str:\n    return DEST_PREFIX.rstrip(\"/\") if DEST_PREFIX else \"\"\n\ndef make_key(filename: str, number: Optional[str] = None) -> str:\n    p = _prefix()\n    if number:\n        base = f\"{p}/{number}\" if p else number\n        return f\"{base}/{filename}\"\n    return f\"{p}/{filename}\" if p else filename\n\ndef s3_put_bytes(key: str, body: bytes, content_type: Optional[str] = None):\n    extra = {\"ContentType\": content_type} if content_type else {}\n    s3.put_object(Bucket=S3_BUCKET, Key=key, Body=body, **extra)\n\ndef s3_put_json(key: str, obj: dict):\n    s3.put_object(\n        Bucket=S3_BUCKET,\n        Key=key,\n        Body=json.dumps(obj, ensure_ascii=False, separators=(\",\", \":\")).encode(\"utf-8\"),\n        ContentType=\"application/json\",\n    )\n\ndef get_password() -> str:\n    if SECRET_ID:\n        r = secrets.get_secret_value(SecretId=SECRET_ID)\n        if \"SecretString\" in r and r[\"SecretString\"]:\n            try:\n                js = json.loads(r[\"SecretString\"])\n                return js.get(\"SN_PASS\") or js.get(\"password\") or next(\n                    (v for v in js.values() if isinstance(v, str)), SN_PASS\n                )\n            except json.JSONDecodeError:\n                return r[\"SecretString\"]\n    return SN_PASS\n\ndef auth_header() -> Dict[str, str]:\n    token = base64.b64encode(f\"{SN_USER}:{get_password()}\".encode()).decode()\n    return {\"Authorization\": f\"Basic {token}\", \"Accept\": \"application/json\"}\n\ndef http_get(url: str, params: Optional[dict] = None, stream: bool = False, timeout=(10, 60)) -> requests.Response:\n    resp = HTTP.get(url, headers=auth_header(), params=params, stream=stream, timeout=timeout)\n    resp.raise_for_status()\n    return resp\n\n# ── KB id handling ───────────────────────────────────────────────\nKB_RE = re.compile(r\"^KB\\d{4,}$\", re.IGNORECASE)\n\ndef coerce_kb_number(*candidates: Optional[str]) -> Optional[str]:\n    for raw in candidates:\n        s = (raw or \"\").strip().upper()\n        if not s:\n            continue\n        if KB_RE.match(s):\n            return s\n        m = re.search(r\"(\\d{4,})\", s)\n        if m:\n            return f\"KB{m.group(1).zfill(7)}\"\n    return None\n\ndef build_sn_url(number: str) -> str:\n    try:\n        return SN_URL_TEMPLATE.format(base=SN_BASE, number=(number or \"\").strip())\n    except Exception:\n        return \"\"\n\ndef guess_content_type(name: str) -> str:\n    return (mimetypes.guess_type(name)[0] or \"application/octet-stream\").lower()\n\ndef to_text(v: Any) -> str:\n    if v is None:\n        return \"\"\n    if isinstance(v, (str, int, float, bool)):\n        return str(v)\n    if isinstance(v, dict):\n        for k in (\"display_value\", \"display\", \"name\", \"label\", \"text\", \"value\"):\n            if k in v and v[k]:\n                return str(v[k])\n        for x in v.values():\n            if isinstance(x, (str, int, float, bool)) and x:\n                return str(x)\n        return \"\"\n    if isinstance(v, (list, tuple, set)):\n        parts = []\n        for x in v:\n            if len(parts) >= 5:\n                break\n            t = to_text(x)\n            if t:\n                parts.append(t)\n        return \", \".join(parts)\n    try:\n        return v.decode(\"utf-8\", errors=\"ignore\") if isinstance(v, (bytes, bytearray)) else str(v)\n    except Exception:\n        return \"\"\n\ndef clamp(v: Any, n: int) -> str:\n    return to_text(v)[:n]\n\ndef display_only(v: Any) -> str:\n    if isinstance(v, dict):\n        for k in (\"display_value\", \"display\", \"name\", \"label\", \"value\", \"text\"):\n            if v.get(k):\n                return str(v[k]).strip()\n        return \"\"\n    s = to_text(v).strip()\n    return \"\" if s.startswith(\"http\") else s\n\ndef enforce_metadata_budget(meta_blocks: dict, budget_bytes: int) -> dict:\n    def packed_size(m: dict) -> int:\n        return len(json.dumps({\"metadataAttributes\": m}, separators=(\",\", \":\")).encode(\"utf-8\"))\n\n    mb = json.loads(json.dumps(meta_blocks))\n    if packed_size(mb) <= budget_bytes:\n        return mb\n\n    nf = mb.get(\"nonFilterable\", {})\n    for key, maxlen in [(\"title\", 256), (\"author\", 120), (\"created_by\", 120)]:\n        if key in nf and isinstance(nf[key], str) and len(nf[key]) > maxlen:\n            nf[key] = nf[key][:maxlen].rstrip()\n    if packed_size(mb) <= budget_bytes:\n        return mb\n\n    for k in [\"author\", \"created_by\"]:\n        if k in nf:\n            nf.pop(k, None)\n            if packed_size(mb) <= budget_bytes:\n                return mb\n\n    f = mb.get(\"filterable\", {})\n    if \"kb_category\" in f:\n        f.pop(\"kb_category\", None)\n    return mb\n\ndef build_metadata_blocks(\n    *,\n    number: str,\n    kb_category: Optional[str],\n    content_type: str,\n    title: str,\n    author: Optional[str],\n    sys_id: str,\n    created_by: Optional[str],\n    sn_url: str,\n) -> dict:\n    filterable = {\n        \"number\": (number or \"\").strip()[:80],\n        \"kb_category\": display_only(kb_category)[:80],\n        \"content_type\": (content_type or \"\").strip()[:40],\n    }\n\n    # Filterable safety (keep tiny)\n    filterable_size = len(json.dumps(filterable, separators=(\",\", \":\")).encode(\"utf-8\"))\n    if filterable_size > 2048:\n        if len(filterable.get(\"kb_category\", \"\")) > 40:\n            filterable[\"kb_category\"] = filterable[\"kb_category\"][:40]\n        filterable_size = len(json.dumps(filterable, separators=(\",\", \":\")).encode(\"utf-8\"))\n        if filterable_size > 2048:\n            filterable[\"number\"] = filterable[\"number\"][:40]\n\n    non_filterable = {\n        \"sn_url\": (sn_url or \"\").strip(),\n        \"title\": (title or \"\").strip()[:512],\n        \"author\": display_only(author)[:256],\n        \"sys_id\": (sys_id or \"\").strip(),\n        \"created_by\": display_only(created_by)[:256],\n    }\n    non_filterable = {k: v for k, v in non_filterable.items() if v}\n\n    meta_blocks = {\"filterable\": filterable, \"nonFilterable\": non_filterable}\n    return enforce_metadata_budget(meta_blocks, MAX_METADATA_BYTES)\n\n# ───────────────────────── KB restriction ──────────────────────\ndef get_kb_sys_id_by_name(name: str) -> Optional[str]:\n    # NOTE: No debug printing of URL or full SN responses (public-safe)\n    q_exact = f\"title={name}^ORname={name}\"\n    url = f\"{KB_BASE_TABLE}?sysparm_query={q_exact}&sysparm_fields=sys_id,title,name&sysparm_limit=5\"\n    rows = http_get(url).json().get(\"result\", []) or []\n    if rows:\n        rows.sort(key=lambda r: (\n            str(r.get(\"title\", \"\")).lower() != name.lower() and\n            str(r.get(\"name\", \"\")).lower()  != name.lower()\n        ))\n        return rows[0].get(\"sys_id\")\n\n    q_like = f\"titleLIKE{name}^ORnameLIKE{name}\"\n    url = f\"{KB_BASE_TABLE}?sysparm_query={q_like}&sysparm_fields=sys_id,title,name&sysparm_limit=10\"\n    rows = http_get(url).json().get(\"result\", []) or []\n    if not rows:\n        return None\n\n    def contains_name(row: dict) -> bool:\n        combined = (str(row.get(\"title\", \"\")) + str(row.get(\"name\", \"\"))).lower()\n        return name.lower() in combined\n\n    rows.sort(key=lambda r: not contains_name(r))\n    return rows[0].get(\"sys_id\")\n\n# ─────────────────────── SN fetchers (articles) ─────────────────\ndef list_kb_articles(kb_sys_id: str, page_size: int, cap: int, strict_published: bool) -> List[Dict[str, str]]:\n    results: List[Dict[str, str]] = []\n    offset = 0\n\n    def fetch_page(q: str, off: int):\n        fields = \"sys_id,number,short_description,kb_knowledge_base,workflow_state\"\n        url = (f\"{KB_TABLE_API}?sysparm_query={q}\"\n               f\"&sysparm_fields={fields}&sysparm_limit={page_size}&sysparm_offset={off}\")\n        return http_get(url).json().get(\"result\", []) or []\n\n    q_state = \"workflow_state=published^\" if strict_published else \"\"\n    while True:\n        q = f\"kb_knowledge_base={kb_sys_id}^{q_state}\".rstrip(\"^\")\n        batch = fetch_page(q, offset)\n        if not batch:\n            break\n        for row in batch:\n            results.append({\n                \"sys_id\": row.get(\"sys_id\", \"\"),\n                \"number\": row.get(\"number\", \"\") or \"\",\n                \"short_description\": row.get(\"short_description\", \"\") or \"\",\n            })\n            if cap > 0 and len(results) >= cap:\n                return results\n        if len(batch) < page_size:\n            break\n        offset += page_size\n\n    return results\n\ndef get_article_content(sys_id: str) -> dict:\n    url = f\"{ARTICLE_CONTENT_API}{sys_id}?fields=kb_knowledge_base\"\n    return http_get(url).json().get(\"result\", {}) or {}\n\ndef get_article_table_row(sys_id: str) -> dict:\n    fields = \",\".join([\n        \"sys_id\",\"number\",\"short_description\",\"workflow_state\",\n        \"sys_created_on\",\"sys_created_by\",\"sys_updated_on\",\"sys_updated_by\",\n        \"kb_category\",\"kb_knowledge_base\",\"valid_from\",\"valid_to\",\"author\",\"sys_view_count\"\n    ])\n    params = {\"sysparm_fields\": fields, \"sysparm_display_value\": \"true\", \"sysparm_limit\": \"1\"}\n    url = f\"{KB_TABLE_API}/{sys_id}\"\n    res = http_get(url, params=params).json().get(\"result\") or {}\n    res.setdefault(\"sys_view_count\", 0)\n    return res\n\ndef list_attachments_for_article(article_sys_id: str) -> List[dict]:\n    all_rows: List[dict] = []\n    limit = 200\n    offset = 0\n    while True:\n        q = f\"table_name=kb_knowledge^table_sys_id={article_sys_id}\"\n        url = (f\"{ATTACH_LIST_API}?sysparm_query={q}\"\n               f\"&sysparm_fields=sys_id,file_name,content_type,sys_updated_on&sysparm_limit={limit}&sysparm_offset={offset}\")\n        res = http_get(url).json().get(\"result\", []) or []\n        all_rows.extend(res)\n        if len(res) < limit:\n            break\n        offset += limit\n    return all_rows\n\ndef download_attachment_bytes(attach_sys_id: str) -> bytes:\n    url = f\"{ATTACH_DOWNLOAD}{attach_sys_id}/file\"\n    return http_get(url, stream=True).content\n\n# ─────────────────────── writers (HTML + attachments) ───────────────────────\n_TAG_RE = re.compile(r\"<[^>]+>\")\n\ndef _html_to_plain_text(html: str) -> str:\n    txt = _TAG_RE.sub(\" \", html or \"\")\n    return re.sub(r\"\\s+\", \" \", txt).strip()\n\ndef _simple_meta(file_name: str, number: str, short_desc: str, sys_id: str, link: str) -> dict:\n    return {\n        \"file_name\": file_name,\n        \"metadata\": {\n            \"number\": number or \"\",\n            \"short_description\": short_desc or \"\",\n            \"sys_id\": sys_id or \"\",\n            \"file_name\": file_name,\n            \"link\": link or \"\"\n        }\n    }\n\ndef write_html_and_sidecar(table_row: dict, detail: dict) -> bool:\n    content = detail.get(\"content\")\n    number  = coerce_kb_number(detail.get(\"number\"), table_row.get(\"number\"))\n    sys_id  = detail.get(\"sys_id\", \"\")\n    short   = detail.get(\"short_description\") or table_row.get(\"short_description\") or \"\"\n\n    if not content:\n        return False\n\n    ident = number or sys_id\n    if not ident:\n        return False\n\n    html_name = f\"{ident}.html\"\n    html_key  = make_key(html_name, ident)\n    s3_put_bytes(html_key, content.encode(\"utf-8\"), \"text/html; charset=utf-8\")\n\n    if GENERATE_TEXT_FROM_HTML:\n        text_key = make_key(f\"{ident}.txt\", ident)\n        s3_put_bytes(text_key, _html_to_plain_text(content).encode(\"utf-8\"), \"text/plain; charset=utf-8\")\n\n    link = build_sn_url(number or \"\")\n    title_val = clamp(short or \"Untitled\", TITLE_MAX_CHARS)\n    meta_blocks = build_metadata_blocks(\n        number=number or \"\",\n        kb_category=table_row.get(\"kb_category\"),\n        content_type=\"text/html\",\n        title=title_val,\n        author=table_row.get(\"author\"),\n        sys_id=sys_id,\n        created_by=table_row.get(\"sys_created_by\"),\n        sn_url=link,\n    )\n\n    sidecar = {\n        \"number\": number or \"\",\n        \"sys_id\": sys_id,\n        \"title\": title_val,\n        \"sn_url\": link,\n        \"sys_updated_on\": table_row.get(\"sys_updated_on\"),\n        \"sys_created_on\": table_row.get(\"sys_created_on\"),\n        \"author\": display_only(table_row.get(\"author\")),\n        \"created_by\": display_only(table_row.get(\"sys_created_by\")),\n        \"workflow_state\": table_row.get(\"workflow_state\"),\n        \"valid_from\": table_row.get(\"valid_from\") or \"\",\n        \"valid_to\": table_row.get(\"valid_to\"),\n        \"kb_category\": display_only(table_row.get(\"kb_category\")),\n        \"sys_view_count\": int(table_row.get(\"sys_view_count\") or 0),\n        \"html_key\": html_name,\n        \"metadataAttributes\": meta_blocks,\n        \"simple_metadata\": _simple_meta(\n            file_name=html_name,\n            number=number or \"\",\n            short_desc=short or \"\",\n            sys_id=sys_id,\n            link=link,\n        ),\n    }\n\n    if LOG_METADATA_BYTES:\n        sz = len(json.dumps({\"metadataAttributes\": sidecar[\"metadataAttributes\"]}, separators=(\",\", \":\")).encode(\"utf-8\"))\n        log.info(f\"[sidecar] html metaBytes={sz}\")\n\n    s3_put_json(html_key + \".metadata.json\", sidecar)\n    return True\n\ndef write_attachment_and_sidecar(table_row: dict, article_detail: dict, att_row: dict) -> bool:\n    number  = coerce_kb_number(article_detail.get(\"number\"), table_row.get(\"number\"))\n    sys_id  = article_detail.get(\"sys_id\", \"\")\n    short   = article_detail.get(\"short_description\") or table_row.get(\"short_description\") or \"\"\n    ident   = number or sys_id\n    if not ident:\n        return False\n\n    att_id = att_row.get(\"sys_id\", \"\")\n    fname  = (att_row.get(\"file_name\") or \"\").strip()\n    if not (att_id and fname):\n        return False\n\n    ext = fname.rsplit(\".\", 1)[-1].lower() if \".\" in fname else \"\"\n    if ATTACH_EXT_WHITELIST and ext not in ATTACH_EXT_WHITELIST:\n        return False\n\n    body = download_attachment_bytes(att_id)\n    if MAX_FILE_BYTES > 0 and len(body) > MAX_FILE_BYTES:\n        log.info(f\"[skip oversize] ({len(body)} > {MAX_FILE_BYTES})\")\n        return False\n\n    ctype = guess_content_type(fname)\n    key   = make_key(fname, ident)\n    s3_put_bytes(key, body, ctype)\n\n    link = build_sn_url(number or \"\")\n    title_val = clamp(short or fname, TITLE_MAX_CHARS)\n    meta_blocks = build_metadata_blocks(\n        number=number or \"\",\n        kb_category=table_row.get(\"kb_category\"),\n        content_type=ctype,\n        title=title_val,\n        author=table_row.get(\"author\"),\n        sys_id=sys_id,\n        created_by=table_row.get(\"sys_created_by\"),\n        sn_url=link,\n    )\n\n    sidecar = {\n        \"number\": number or \"\",\n        \"sys_id\": sys_id,\n        \"title\": title_val,\n        \"sn_url\": link,\n        \"sys_updated_on\": table_row.get(\"sys_updated_on\"),\n        \"sys_created_on\": table_row.get(\"sys_created_on\"),\n        \"author\": display_only(table_row.get(\"author\")),\n        \"created_by\": display_only(table_row.get(\"sys_created_by\")),\n        \"workflow_state\": table_row.get(\"workflow_state\"),\n        \"valid_from\": table_row.get(\"valid_from\") or \"\",\n        \"valid_to\": table_row.get(\"valid_to\"),\n        \"kb_category\": display_only(table_row.get(\"kb_category\")),\n        \"sys_view_count\": int(table_row.get(\"sys_view_count\") or 0),\n        \"file_key\": fname,\n        \"metadataAttributes\": meta_blocks,\n        \"simple_metadata\": _simple_meta(\n            file_name=fname,\n            number=number or \"\",\n            short_desc=short or \"\",\n            sys_id=sys_id,\n            link=link,\n        ),\n    }\n\n    if LOG_METADATA_BYTES:\n        sz = len(json.dumps(sidecar, separators=(\",\", \":\")).encode(\"utf-8\"))\n        log.info(f\"[sidecar] att metaBytes={sz}\")\n\n    s3_put_json(key + \".metadata.json\", sidecar)\n    return True\n\n# ─────────────────────── core pipeline ────────────────────────\ndef process_article(sys_id: str, start_ts: float) -> int:\n    total = 0\n    table_row = get_article_table_row(sys_id)\n    detail    = get_article_content(sys_id)\n\n    if detail.get(\"content\"):\n        if write_html_and_sidecar(table_row, detail):\n            total += 1\n\n    api_atts = detail.get(\"attachments\") or []\n    tbl_atts = list_attachments_for_article(sys_id)\n    seen_ids = {a.get(\"sys_id\") for a in api_atts if a.get(\"sys_id\")}\n    all_atts = api_atts + [t for t in tbl_atts if t.get(\"sys_id\") not in seen_ids]\n\n    embedded = detail.get(\"embedded_content\") or []\n    for emb in embedded:\n        emb_id = emb.get(\"sys_id\") or emb.get(\"id\") or emb.get(\"attachment_sys_id\")\n        emb_fn = (emb.get(\"file_name\") or emb.get(\"name\") or \"\").strip()\n        if not emb_id or not emb_fn:\n            continue\n        if emb_id in seen_ids:\n            continue\n        all_atts.append({\"sys_id\": emb_id, \"file_name\": emb_fn})\n        seen_ids.add(emb_id)\n\n    for att in all_atts:\n        if time.time() - start_ts > STOP_AFTER_SECONDS:\n            log.info(\"Time guard hit during attachments; stopping.\")\n            break\n        try:\n            if write_attachment_and_sidecar(table_row, detail, att):\n                total += 1\n        except requests.HTTPError as e:\n            log.warning(f\"[att-dl-failed] {e.__class__.__name__}\")\n\n    return total\n\n# ─────────────────────── lambda entry ──────────────────────────\ndef handler(event, context):\n    \"\"\"\n    Example event:\n      {\"limit\": 0, \"offset\": 0, \"page_size\": 200, \"knowledgeBaseName\": \"Your KB Name\"}\n    \"\"\"\n    cfg_err = validate_runtime_config()\n    if cfg_err:\n        return cfg_err\n\n    wanted_name = (event.get(\"knowledgeBaseName\") if isinstance(event, dict) else None) or KNOWLEDGE_BASE_NAME\n    page_size   = int((event.get(\"page_size\") if isinstance(event, dict) else None) or PAGE_SIZE)\n    cap_env     = int((event.get(\"limit\") if isinstance(event, dict) else None) or ARTICLES_LIMIT or 0)\n    offset      = int((event.get(\"offset\") if isinstance(event, dict) else 0) or 0)\n\n    # Public-safe log (no bucket name, no instance URL, no secrets)\n    log.info(f\"Start sync: KB='{wanted_name}', page_size={page_size}, cap={cap_env or 'ALL'}, offset={offset}\")\n\n    kb_sys_id = get_kb_sys_id_by_name(wanted_name)\n    if not kb_sys_id:\n        return {\"status\": \"error\", \"type\": \"kb_not_found\", \"message\": \"Knowledge base not found.\"}\n\n    start_ts  = time.time()\n    rows_all  = list_kb_articles(kb_sys_id, page_size=200, cap=(cap_env or 0), strict_published=STRICT_PUBLISHED)\n    log.info(f\"[stats] articles_total={len(rows_all)} strict_published={STRICT_PUBLISHED}\")\n\n    # NOTE: Your processing loop is currently commented out in the original file.\n    # Keep as-is for your POC behavior:\n    return {\"status\": \"ok\", \"message\": \"done\"}\n\ndef lambda_handler(event, context):\n    return handler(event, context)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}